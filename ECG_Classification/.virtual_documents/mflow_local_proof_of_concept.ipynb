


import os
from datetime import datetime, timezone
import boto3
import mlflow
from dotenv import load_dotenv


# Initialization of environment variables
load_dotenv(override=True)


# Hyperparamters
max_depth = 4


tracking_uri = os.environ.get("MLFLOW_TRACKING_ARN")
experiment_name = os.environ.get("MLFLOW_EXPERIMENT_NAME", "Default")
print(f"Target Tracking URI: {tracking_uri}")
print(f"Target Experiment: {experiment_name}")


# Verify environment variables are actually loaded
tracking_uri = os.environ.get("MLFLOW_TRACKING_ARN")
experiment_name = os.environ.get("MLFLOW_EXPERIMENT_NAME", "Default")
artifact_bucket_name = os.environ.get("ML_FLOW_ARTIFACT_S3_BUCKET_NAME")
print(f"Target Tracking URI: {tracking_uri}")
print(f"Target Experiment: {experiment_name}")
print(f"Bucket name: {artifact_bucket_name}")

# Set the Tracking Server URI using the ARN of the Tracking Server you created
mlflow.set_tracking_uri(tracking_uri)

# We see if we can create an experiment
try:
    # NOTE: Dec 26, 2025: with local development, we need to send it to the tracking server,
    # then from that server it will be sent to s3. If we want to prefix the artifacts
    mlflow.create_experiment(
        name=experiment_name, artifact_location=f"mlflow-artifacts:/{experiment_name}"
    )
    print(f"Experiment {experiment_name} created successfully!")
except:
    print(f"Experiment {experiment_name} already exists. Using existing settings.")
mlflow.set_experiment(experiment_name)
# Starting the run explicity
date_now = datetime.now(timezone.utc)
utc = round(date_now.timestamp() * 1000)
# defining a job name
ml_job_name = f"decisionTree-run-at-{utc}-max_depth={max_depth}"
with mlflow.start_run(run_name=ml_job_name) as run:
    print(f"Artifact URI for this run: {run.info.artifact_uri}")
    mlflow.autolog()
    mlflow.log_param("env", "Ubuntu_WSL")
    mlflow.log_metric("status", 1.0)
    print("Log successful! Check the UI.")
    with open("proxy_test.txt", "w") as f:
        f.write("If this is in S3, the Ngrok proxy is 100% working!")

    # Send it to the server
    mlflow.log_artifact("proxy_test.txt")

    print("Log successful! Check the UI and S3.")






